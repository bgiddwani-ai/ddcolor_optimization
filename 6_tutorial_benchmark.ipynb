{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tritonclient[all]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tritonclient.http as httpclient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Setup Triton Client & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connected to Triton and model 'ddcolor_trt' is ready.\n"
     ]
    }
   ],
   "source": [
    "TRITON_URL = \"10.67.32.50:8000\"\n",
    "MODEL_NAME = \"ddcolor_trt\"\n",
    "BATCH_SIZE = 8\n",
    "IMAGE_SIZE = (512, 512)\n",
    "\n",
    "client = httpclient.InferenceServerClient(url=TRITON_URL)\n",
    "if client.is_model_ready(MODEL_NAME):\n",
    "    print(f\"✅ Connected to Triton and model '{MODEL_NAME}' is ready.\")\n",
    "else:\n",
    "    raise RuntimeError(\"❌ Model not ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: Define Preprocessing & Postprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img_path, image_size=(512, 512)):\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Cannot read {img_path}\")\n",
    "\n",
    "    orig_size = (img.shape[1], img.shape[0])\n",
    "    rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
    "    lab = cv2.cvtColor(rgb, cv2.COLOR_RGB2LAB)\n",
    "    l = lab[:, :, 0:1]\n",
    "    gray_lab = np.concatenate([l, np.zeros_like(l), np.zeros_like(l)], axis=-1)\n",
    "    gray_rgb = cv2.cvtColor(gray_lab, cv2.COLOR_LAB2RGB)\n",
    "    gray_rgb = cv2.resize(gray_rgb, image_size)\n",
    "    inp = gray_rgb.transpose(2, 0, 1).astype(np.float32)\n",
    "    return inp, l, orig_size\n",
    "\n",
    "\n",
    "\n",
    "def postprocess_image(output_ab, orig_l, orig_size):\n",
    "    W, H = orig_size\n",
    "    ab = cv2.resize(output_ab.transpose(1, 2, 0), (W, H))\n",
    "    lab_out = np.concatenate([orig_l, ab], axis=-1)\n",
    "    rgb = cv2.cvtColor(lab_out, cv2.COLOR_LAB2RGB)\n",
    "    rgb = np.clip(rgb, 0, 1)\n",
    "    return (rgb * 255).astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4: Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_batch(batch_array):\n",
    "    inputs = [httpclient.InferInput(\"input\", batch_array.shape, \"FP32\")]\n",
    "    inputs[0].set_data_from_numpy(batch_array)\n",
    "    outputs = [httpclient.InferRequestedOutput(\"output\")]\n",
    "    result = client.infer(model_name=MODEL_NAME, inputs=inputs, outputs=outputs)\n",
    "    out_array = result.as_numpy(\"output\")\n",
    "    return out_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './grayscale_images/Audrey Hepburn.jpg'\n",
    "inp, l, s = preprocess_image(str(path), IMAGE_SIZE)\n",
    "\n",
    "img_gray_rgb = np.expand_dims(inp, axis=0)\n",
    "img_gray_rgb = np.concatenate([img_gray_rgb for _ in range(BATCH_SIZE)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time per batch: 0.1684 seconds\n",
      "Average time per image: 0.0210 seconds\n",
      "Average FPS per image: 47.5140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "times = []\n",
    "for i in tqdm.tqdm(range(10)):\n",
    "    start = time.time()\n",
    "    output = infer_batch(img_gray_rgb)\n",
    "    times.append(time.time() - start)\n",
    "\n",
    "print(f\"Average time per batch: {np.mean(times):.4f} seconds\")\n",
    "print(f\"Average time per image: {np.mean(times)/BATCH_SIZE:.4f} seconds\")\n",
    "print(f\"Average FPS per image: {BATCH_SIZE/np.mean(times):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
